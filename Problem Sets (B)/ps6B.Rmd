---
title: "STAT 231: Problem Set 6B"
author: "Alastair Poole"
date: "due by 10 PM on Friday, April 2"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

This homework assignment is designed to help you further ingest, practice, and expand upon the material covered in class over the past week(s).  You are encouraged to work with other students, but all code and text must be written by you, and you must indicate below who you discussed the assignment with (if anyone).  

Steps to proceed:

\begin{enumerate}
\item In RStudio, go to File > Open Project, navigate to the folder with the course-content repo, select the course-content project (course-content.Rproj), and click "Open" 
\item Pull the course-content repo (e.g. using the blue-ish down arrow in the Git tab in upper right window)
\item Copy ps6B.Rmd from the course repo to your repo (see page 6 of the GitHub Classroom Guide for Stat231 if needed)
\item Close the course-content repo project in RStudio
\item Open YOUR repo project in RStudio
\item In the ps6B.Rmd file in YOUR repo, replace "YOUR NAME HERE" with your name
\item Add in your responses, committing and pushing to YOUR repo in appropriate places along the way
\item Run "Knit PDF" 
\item Upload the pdf to Gradescope.  Don't forget to select which of your pages are associated with each problem.  \textit{You will not get credit for work on unassigned pages (e.g., if you only selected the first page but your solution spans two pages, you would lose points for any part on the second page that the grader can't see).} 
\end{enumerate}

```{r, setup, include=FALSE}
library(tidyverse)
library(tidytext)
library(wordcloud)
library(textdata)
library(ggpubr)

knitr::opts_chunk$set(
  tidy=FALSE,     # display code as typed
  size="small")   # slightly smaller font for code
```


\newpage 
# If you discussed this assignment with any of your peers, please list who here:

> ANSWER: Brandon Kwon

\newpage
# Trump Tweets

David Robinson, Chief Data Scientist at DataCamp, wrote a blog post ["Text analysis of Trump's tweets confirms he writes only the (angrier) Android half"](http://varianceexplained.org/r/trump-tweets/).

He provides a dataset with over 1,500 tweets from the account realDonaldTrump between 12/14/2015 and 8/8/2016.  We'll use this dataset to explore the tweeting behavior of realDonaldTrump during this time period.

First, read in the file. Note that there is a `TwitteR` package which provides an interface to the Twitter web API.  We'll use this R dataset David created using that package so that you don't have to set up Twitter authentication.  

```{r}
load(url("http://varianceexplained.org/files/trump_tweets_df.rda"))
```

## A little wrangling to warm-up

1a.  There are a number of variables in the dataset we won't need.  

- First, confirm that all the observations in the dataset are from the screen-name `realDonaldTrump`.  

- Then, create a new dataset called `tweets` that only includes the following variables:

- `text`
- `created`
- `statusSource`

```{r}
#this verifies that all observations are from "realDonaldTrump"
#because I counted all observations not written by him and there are none
#in this dataset
trump_tweets_df %>%
filter(screenName != "realDonaldTrump") %>%
count

#Creating new dataset
tweets <- trump_tweets_df %>%
  select(c(text, created, statusSource))

  
```

\newpage
1b. Using the `statusSource` variable, compute the number of tweets from each source.  How many different sources are there?  How often are each used?

> ANSWER: There are five different sources, the number of tweets form each source, respectively, is 1, 120, 1, 762, 628. 

```{r}
num_sources <- tweets %>%
  group_by(statusSource) %>%
  summarise(freq = n())
num_sources
```

\newpage
1c. We're going to compare the language used between the Android and iPhone sources, so only want to keep tweets coming from those sources.  Explain what the `extract` function (from the `tidyverse` package) is doing below.  Include in your own words what each argument is doing.  (Note that "regex" stands for "regular expression".)

> ANSWER: The extract function looks at observations from the statusSource column, and creates  a new column called "source". Then it scans the observations from statusSource for the expression "Twitter for" (followed by any number of other characters) and then extracts whatever follows this expression "Twitter for" (this could include N/A if nothing follows the expression). Finally, filtering for either Android or iPhone selects only the rows that contain the strings "Android" or "iPhone" following "Twitter for". The "col = statusSource" argument indicates that extract will be scanning observations in the column called "statusSource". The "into = 'source'" argument indicates that the desired observations are put into a new column called "source". The "regex = 'Twitter for (.*)<'" argument indicates that extract will be looking for that particular phrase followed by any number of other characters. The "remove = FALSE" argument indicates that extract will not throw away the original statusSource column after extraction. Finally, the filter argument indicates that we are only selected rows that contain either "Android" or "iPhone" and placing these into the new column.

```{r}
tweets2 <- tweets %>%
  extract(col = statusSource, into = "source"
          , regex = "Twitter for (.*)<"
          , remove = FALSE) %>%
  filter(source %in% c("Android", "iPhone"))
```


\newpage
## How does the language of the tweets differ by source?  

2a. Create a word cloud for the top 50 words used in tweets sent from the Android.  Create a second word cloud for the top 50 words used in tweets sent from the iPhone.  How do these word clouds compare?  (Are there some common words frequently used from both sources? Are the most common words different between the sources?)

*Don't forget to remove stop words before creating the word cloud.  Also remove the terms "https" and "t.co".*

> ANSWER: It appears as though the Android wordcloud demonstrates that Trump's tweets include words that focus on combating his political opponents, while the iPhone wordcloud demonstrates that Trump used vocabulary to support himself rather than try and knock down his adversaries. This can be seen because the Android wordcloud includes very visible words such as "Hillary" and "crooked" (and also "Bernie" and "Cruz"), whereas the iPhone wordcloud includes words such as "enjoy", and "America". Words that appear in both sources include "Hillary", "America", and "makeamericagreatagain".

```{r, fig.width=8, fig.height=8}
#First create dataset where each word results in a distinct observation
tweets_words <- tweets2 %>%
  unnest_tokens(output = word, input = text)

#Removes stop words and "https" and "t.co"
tweets_words2 <- tweets_words %>%
  anti_join(stop_words, by="word") %>%
  filter(word != "https") %>%
  filter(word != "t.co")

#Creates two datasets just for iPhone and Android tweets respectively
#Use count function to count the occurrence of each word
tweets_iPhone <- tweets_words2 %>%
  filter(source == "iPhone") %>%
  count(word, sort = TRUE)
tweets_Android <- tweets_words2 %>%
  filter(source == "Android") %>%
  count(word, sort = TRUE)

#Wordcloud for Android
tweets_Android %>%
  with(wordcloud(words = word, freq = n, max.words=50))

#Wordcloud for iPhone
tweets_iPhone %>%
  with(wordcloud(words = word, freq = n, max.words=50))


```

\newpage
2b. Create a visualization that compares the top 10 *bigrams* appearing in tweets by each source (that is, facet by source).  After creating a dataset with one row per bigram, you should remove any rows that contain a stop word within the bigram.  

How do the top used bigrams compare between the two sources?

> ANSWER: In both sources, "Crooked Hillary" and "Hillary Clinton" are in the top three bigrams used. However, on Trump's Android, there is no bigram that even mentions him until the 7th most popular, while on his iPhone, the name "Trump" is contained in the most popular bigram. In the Android source, it looks as though Trump's most frequently used bigrams were all talking bad about his opponents, while on his iPhone he talked about Hillary Clinton but otherwise made an effort to promote himself with positive, 'America first' type bigrams.

```{r}
Android_bigrams <- tweets2 %>%
  #Creates dataset with top-10
  filter(source == "Android") %>%
  unnest_tokens(output = bigram, input = text, token = "ngrams", n = 2) %>%
  separate(bigram, into = c("first", "second"), sep = " ", remove = FALSE) %>%
  anti_join(stop_words, by = c("first" = "word")) %>%
  anti_join(stop_words, by = c("second" = "word")) %>%
  filter(str_detect(first, "[a-z]") & str_detect(second, "[a-z]")) %>%
  filter(!str_detect(first, 'https') & !str_detect(second, 'https')) %>%
   filter(!str_detect(first, 't.co') & !str_detect(second, 't.co')) %>%
  count(bigram, sort = TRUE) %>%
  slice(1:10)

iPhone_bigrams <- tweets2 %>%
  #Creates dataset with top-10
  filter(source == "iPhone") %>%
  unnest_tokens(output = bigram, input = text, token = "ngrams", n = 2) %>%
  separate(bigram, into = c("first", "second"), sep = " ", remove = FALSE) %>%
  anti_join(stop_words, by = c("first" = "word")) %>%
  anti_join(stop_words, by = c("second" = "word")) %>%
  filter(str_detect(first, "[a-z]") & str_detect(second, "[a-z]")) %>%
  filter(!str_detect(first, 'https') & !str_detect(second, 'https')) %>%
   filter(!str_detect(first, 't.co') & !str_detect(second, 't.co')) %>%
  count(bigram, sort = TRUE) %>%
  slice(1:10)

graph1 <- Android_bigrams %>%
  #Creates graph
  ggplot(aes(x = reorder(bigram,n), y = n, color = bigram, fill=bigram)) +
  geom_col() +
  xlab(NULL) +
  coord_flip() +
  labs(y = "Occurrences"
       , title="Bigrams Android") +
  guides(color = "none", fill = "none")

graph2 <- iPhone_bigrams %>%
  #Creates graph
  ggplot(aes(x = reorder(bigram,n), y = n, color = bigram, fill=bigram)) +
  geom_col() +
  xlab(NULL) +
  coord_flip() +
  labs(y = "Occurrences"
       , title="Bigrams iPhone") +
  guides(color = "none", fill = "none")

#Puts plots next to each other
ggarrange(graph1, graph2, ncol = 2, nrow = 2)
```


\newpage
2c. Consider the sentiment.  Compute the proportion of words among the tweets within each source classified as "angry" and the proportion of words classified as "joy"  based on the NRC lexicon.  How does the proportion of "angry" and "joy" words compare between the two sources?  What about "positive" and "negative" words?  

> ANSWER: The proportion of words Trump tweeted using an Android that are angry is roughly 5.22%, while the proportion of words classified as "joy" is roughly 3.84%. In contrast, the proportion of words Trump tweeted using an iPhone that are angry is roughly 3.7%, while the proportion of words classified as "joy" is roughly 3.54%. So we can see that Trump's use of joyful words is roughly the same between the two sources, but the proportion of angry words within his Android tweets is about 2% more than within his iPhone tweets. In terms of positive and negative words, on the Android, the proportions are as follows: Negative = 9.23%, Positive = 10.55%. On the iPhone the proportions are as follows: Negative = 5.69%, Positive = 9.1%. This also illustrates that his use of positive words is almost the same between the two sources, yet he uses almost twice as many negative words in his Android tweets compared to his iPhone tweets.

```{r}
#Creates the object "nrc_lexicon"
nrc_lexicon <- get_sentiments("nrc")

#Finds total number of words used in tweets
n_android <- sum(tweets_Android$n)

#Finds total number of words used in tweets
n_iPhone <- sum(tweets_iPhone$n)

#Creates dataset
Android_sentiment <-
  merge(tweets_Android, nrc_lexicon, by.x = "word", by.y = "word") %>%
  filter(sentiment == "joy" | sentiment == "anger" | 
           sentiment == "positive" | sentiment == "negative") %>%
  #Finds total number of words associated with particular sentiment
  group_by(sentiment) %>%
  summarize(total = sum(n)) %>%
  mutate(proportion = total / n_android)

#Creates dataset
iPhone_sentiment <-
  merge(tweets_iPhone, nrc_lexicon, by.x = "word", by.y = "word") %>%
  filter(sentiment == "joy" | sentiment == "anger" | 
           sentiment == "positive" | sentiment == "negative") %>%
  #Finds total number of words associated with particular sentiment
  group_by(sentiment) %>%
  summarize(total = sum(n)) %>%
  mutate(proportion = total / n_iPhone)

#Shows the respective proportions
Android_sentiment
iPhone_sentiment
```


\newpage
2d. Lastly, based on your responses above, do you think there is evidence to support Robinson's claim that Trump only writes the (angrier) Android half of the tweets from realDonaldTrump?  In 2-4 sentences, please explain.

> ANSWER: Yes, there is evidence to support Robinson's claim that Trump's angrier tweets come from the Android rather than the iPhone. Specifically, in the visualization comparison above, the top six most frequently used bigrams in Trump's Android tweets contain words related to Trump's opponents, and the most popular bigram (by far) across his two sources is "crooked Hillary" which occurs from the Android source. This is when compared to his most popular bigrams from the iPhone source, of which five of the ten most popular are all actively pro Trump and pro America. Next, considering the proportion of angry and negative tweets, we see that negative words appear twice as frequently in his Android tweets than his iPhone tweets, and he uses a significantly higher proportion of angry words in his Android tweets as well. This is while his "joy" and "positive" proportions across the two sources are relative equal, thus giving evidence to support the notion that Trump tweets his angrier tweets from his Android.